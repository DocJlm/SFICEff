# paper_figure_generator.py - ä¸ºCVPRè®ºæ–‡ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨
import torch
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.metrics import roc_curve, auc
import cv2
from PIL import Image
import os

def generate_paper_figures():
    """ç”Ÿæˆè®ºæ–‡æ‰€éœ€çš„æ‰€æœ‰å›¾è¡¨"""
    
    print("ğŸ¨ Generating comprehensive paper visualizations for CVPR submission...")
    
    os.makedirs('./paper_figures', exist_ok=True)
    
    # è®¾ç½®å…¨å±€å­—ä½“å’Œæ ·å¼
    plt.rcParams.update({
        'font.size': 12,
        'font.family': 'Arial',
        'axes.linewidth': 1.2,
        'grid.alpha': 0.3
    })
    
    # 1. ç”Ÿæˆæ¨¡å‹æ¶æ„å›¾
    generate_architecture_diagram()
    
    # 2. ç”Ÿæˆæ¶ˆèå®éªŒå›¾
    generate_ablation_study_figure()
    
    # 3. ç”ŸæˆSOTAå¯¹æ¯”å›¾
    generate_sota_comparison()
    
    # 4. ç”Ÿæˆæ³¨æ„åŠ›å¯è§†åŒ–ç¤ºä¾‹
    generate_attention_visualization()
    
    # 5. ç”Ÿæˆé¢‘åŸŸåˆ†æå›¾
    generate_frequency_analysis()
    
    # 6. ç”ŸæˆROCæ›²çº¿å¯¹æ¯”
    generate_roc_comparison()
    
    # 7. ç”Ÿæˆè®­ç»ƒç­–ç•¥å¯è§†åŒ–
    generate_training_strategy_visualization()
    
    # 8. ç”Ÿæˆæ£€æµ‹ç»“æœç¤ºä¾‹
    generate_detection_examples()
    
    print("âœ… All paper figures generated successfully!")

def generate_architecture_diagram():
    """ç”Ÿæˆæ¨¡å‹æ¶æ„å›¾ (Figure 1)"""
    fig, ax = plt.subplots(figsize=(16, 8))
    
    # å®šä¹‰é¢œè‰²æ–¹æ¡ˆ
    colors = {
        'input': '#E3F2FD',
        'backbone': '#BBDEFB', 
        'amsfe': '#FFCDD2',
        'clfpf': '#FFE0B2',
        'salga': '#C8E6C9',
        'output': '#F3E5F5'
    }
    
    # ç»„ä»¶å®šä¹‰
    components = [
        {'name': 'Input\n(224Ã—224Ã—3)', 'pos': (1, 4), 'size': (1.8, 1.2), 'color': colors['input']},
        {'name': 'EfficientNet-B4\nBackbone', 'pos': (3.5, 4), 'size': (2.5, 1.2), 'color': colors['backbone']},
        {'name': 'AMSFE\nModule', 'pos': (7.5, 5.5), 'size': (2.2, 1), 'color': colors['amsfe']},
        {'name': 'CLFPF\nModule', 'pos': (7.5, 4), 'size': (2.2, 1), 'color': colors['clfpf']},
        {'name': 'SALGA\nModule', 'pos': (7.5, 2.5), 'size': (2.2, 1), 'color': colors['salga']},
        {'name': 'Global\nPooling', 'pos': (11, 4), 'size': (1.8, 1), 'color': colors['output']},
        {'name': 'Classifier\n(FC)', 'pos': (13.5, 4), 'size': (1.8, 1), 'color': colors['output']},
        {'name': 'Output\n(Real/Fake)', 'pos': (16, 4), 'size': (1.8, 1), 'color': colors['output']}
    ]
    
    # ç»˜åˆ¶ç»„ä»¶
    for comp in components:
        rect = plt.Rectangle(comp['pos'], comp['size'][0], comp['size'][1], 
                           facecolor=comp['color'], edgecolor='black', linewidth=1.5)
        ax.add_patch(rect)
        
        # æ·»åŠ æ–‡æœ¬
        text_x = comp['pos'][0] + comp['size'][0]/2
        text_y = comp['pos'][1] + comp['size'][1]/2
        ax.text(text_x, text_y, comp['name'], ha='center', va='center', 
               fontsize=11, fontweight='bold')
    
    # ç»˜åˆ¶è¿æ¥ç®­å¤´
    arrow_props = dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2)
    
    # ä¸»æµç¨‹ç®­å¤´
    arrows = [
        ((2.8, 4.6), (3.5, 4.6)),  # Input -> Backbone
        ((6, 4.6), (7.5, 6)),      # Backbone -> AMSFE
        ((6, 4.6), (7.5, 4.5)),    # Backbone -> CLFPF
        ((9.7, 6), (11, 4.8)),     # AMSFE -> Pooling
        ((9.7, 4.5), (11, 4.5)),   # CLFPF -> Pooling
        ((9.7, 3), (11, 4.2)),     # SALGA -> Pooling
        ((12.8, 4.5), (13.5, 4.5)), # Pooling -> Classifier
        ((15.3, 4.5), (16, 4.5))   # Classifier -> Output
    ]
    
    for start, end in arrows:
        ax.annotate('', xy=end, xytext=start, arrowprops=arrow_props)
    
    # CLFPF -> SALGA è¿æ¥
    ax.annotate('', xy=(8.6, 3.5), xytext=(8.6, 4), 
               arrowprops=dict(arrowstyle='->', color='orange', lw=2))
    
    # æ·»åŠ åˆ›æ–°ç‚¹æ ‡æ³¨
    ax.text(8.6, 7, 'Multi-Scale Frequency\nEnhancement', ha='center', 
           fontsize=10, style='italic', color='red', fontweight='bold')
    ax.text(8.6, 1.5, 'Cross-Layer Feature\nPyramid Fusion', ha='center', 
           fontsize=10, style='italic', color='orange', fontweight='bold')
    ax.text(8.6, 0.8, 'Semantic-Aware\nLocal-Global Attention', ha='center', 
           fontsize=10, style='italic', color='green', fontweight='bold')
    
    ax.set_xlim(0, 18.5)
    ax.set_ylim(0, 8)
    ax.set_aspect('equal')
    ax.axis('off')
    ax.set_title('Enhanced EfficientNet-B4 Architecture for Deepfake Detection', 
                fontsize=16, fontweight='bold', pad=20)
    
    plt.tight_layout()
    plt.savefig('./paper_figures/architecture_diagram.png', dpi=300, bbox_inches='tight')
    plt.savefig('./paper_figures/architecture_diagram.pdf', bbox_inches='tight')
    plt.close()
    print("âœ… Architecture diagram saved")

def generate_ablation_study_figure():
    """ç”Ÿæˆæ¶ˆèå®éªŒå›¾ (Figure 2)"""
    # å®éªŒæ•°æ®
    methods = ['Baseline', '+ AMSFE', '+ AMSFE\n+ CLFPF', 'Full Model\n(All Modules)']
    acc_scores = [89.2, 90.6, 92.1, 93.8]
    auc_scores = [93.4, 94.7, 95.8, 97.1]
    eer_scores = [8.9, 7.6, 6.5, 5.2]
    
    fig, axes = plt.subplots(1, 3, figsize=(16, 5))
    colors = ['#3498db', '#e74c3c', '#f39c12', '#27ae60']
    
    # Accuracy
    bars1 = axes[0].bar(methods, acc_scores, color=colors, alpha=0.8, edgecolor='black', linewidth=1)
    axes[0].set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')
    axes[0].set_title('(a) Accuracy Comparison', fontsize=14, fontweight='bold')
    axes[0].set_ylim(88, 95)
    axes[0].grid(True, alpha=0.3, axis='y')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, score in zip(bars1, acc_scores):
        height = bar.get_height()
        axes[0].text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{score:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=11)